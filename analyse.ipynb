{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "# from src.module.func import scatter_plot, plot_points\n",
    "\n",
    "# 在 Jupyter 中交互式输入文件路径\n",
    "file_path = \"/root/ftg/results/tokencls_agnews_on_imdb.json\"\n",
    "j2 = \"/root/ftg/results/tokencls_agnews.json\"\n",
    "# j1 = input(\"请输入第一个 JSONL 文件的路径: \")\n",
    "# j2 = input(\"请输入第二个 JSONL 文件的路径: \")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [12, 8]\n",
    "plt.rcParams[\"figure.dpi\"] = 200\n",
    "\n",
    "def extract_coordinates(jsonl_file):\n",
    "    \"\"\"Extract coordinates from a JSONL file.\"\"\"\n",
    "    data = []\n",
    "    with open(jsonl_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        result = json.load(f)\n",
    "        for line in result:\n",
    "            data.append(line[0])  # Parse each JSON line\n",
    "\n",
    "    # Extract coordinates\n",
    "    coordinates = []\n",
    "    for entry in data:\n",
    "        coordinates.extend([(item[0], item[1]) for item in entry[\"ig_gold\"]])\n",
    "    return coordinates\n",
    "\n",
    "\n",
    "def filter_counter(counter_obj):\n",
    "    # 计算平均值\n",
    "    mean_value = int(sum(counter_obj.values()) / len(counter_obj))\n",
    "    threshold = int(mean_value * 0)\n",
    "    # threshold = int(mean_value * 0.1)\n",
    "    # 过滤元素\n",
    "    filtered_counter = {\n",
    "        key: value for key, value in counter_obj.items() if value >= threshold\n",
    "    }\n",
    "\n",
    "    return filtered_counter\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def scatter_plot(counter_obj, highlight_duplicates=None):\n",
    "    x = [key[0] for key in counter_obj.keys()]\n",
    "    y = [key[1] for key in counter_obj.keys()]\n",
    "    sizes = [value * 0.1 for value in counter_obj.values()]  # 调整点大小以反映计数\n",
    "\n",
    "    plt.scatter(\n",
    "        x, y, s=sizes, alpha=0.6, color=\"skyblue\", edgecolor=\"black\", label=\"All Points\"\n",
    "    )\n",
    "\n",
    "    # Highlight duplicate points if provided\n",
    "    if highlight_duplicates:\n",
    "        dup_x = [key[0] for key in highlight_duplicates]\n",
    "        dup_y = [key[1] for key in highlight_duplicates]\n",
    "        plt.scatter(dup_x, dup_y, s=1, alpha=0.9, color=\"red\", label=\"Duplicates\")\n",
    "\n",
    "    plt.xlabel(\"X values\")\n",
    "    plt.ylabel(\"Y values\")\n",
    "    plt.title(\"Scatter plot of (x, y) counts\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Extract coordinates from both files\n",
    "coordinates_file1 = extract_coordinates(file_path)\n",
    "coordinates_file2 = extract_coordinates(j2)\n",
    "\n",
    "# Count occurrences in both files\n",
    "counter_file1 = Counter(coordinates_file1)\n",
    "counter_file2 = Counter(coordinates_file2)\n",
    "# counter_file1 = filter_counter(counter_file1)\n",
    "counter_file2 = filter_counter(counter_file2)\n",
    "scatter_plot(counter_file1)\n",
    "scatter_plot(counter_file2)\n",
    "\n",
    "# Find duplicates between the two files\n",
    "total_coordinates_combined = set(counter_file1) | set(counter_file2)\n",
    "duplicate_coordinates = set(counter_file1) & set(counter_file2)\n",
    "complement_1 = set(counter_file1) - set(counter_file2)\n",
    "complement_coord = set(counter_file2) - set(counter_file1)\n",
    "\n",
    "duplicate_count = len(duplicate_coordinates)\n",
    "\n",
    "total_coordinates_file1 = len(set(counter_file1))\n",
    "total_coordinates_file2 = len(set(counter_file2))\n",
    "total_coordinates_combined = len(total_coordinates_combined)\n",
    "total_complement_1 = len(complement_1)\n",
    "total_complement_2 = len(complement_coord)\n",
    "\n",
    "# Calculate duplicate ratios\n",
    "duplicate_ratio_file1 = (\n",
    "    duplicate_count / total_coordinates_file1 if total_coordinates_file1 > 0 else 0\n",
    ")\n",
    "duplicate_ratio_file2 = (\n",
    "    duplicate_count / total_coordinates_file2 if total_coordinates_file2 > 0 else 0\n",
    ")\n",
    "duplicate_ratio_combined = (\n",
    "    duplicate_count / total_coordinates_combined\n",
    "    if total_coordinates_combined > 0\n",
    "    else 0\n",
    ")\n",
    "# 绘制带有重复点标记的散点图\n",
    "\n",
    "scatter_plot(counter_file1, highlight_duplicates=duplicate_coordinates)\n",
    "scatter_plot(counter_file2, highlight_duplicates=duplicate_coordinates)\n",
    "scatter_plot(counter_file1, highlight_duplicates=complement_1)\n",
    "scatter_plot(counter_file2, highlight_duplicates=complement_coord)\n",
    "# 将集合转换为列表，因为 JSON 不支持集合\n",
    "complement_1_list = list(complement_1)\n",
    "complement_2_list = list(complement_coord)\n",
    "\n",
    "# 写入 JSON 文件\n",
    "with open(\"complement_1.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(complement_1_list, f, ensure_ascii=False, indent=4)\n",
    "# 写入 JSON 文件\n",
    "with open(\"complement_2.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(complement_2_list, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"写入完成！\")\n",
    "\n",
    "# Print results\n",
    "print(f\"Total coordinates in file 1: {total_coordinates_file1}\")\n",
    "print(f\"Total coordinates in file 2: {total_coordinates_file2}\")\n",
    "print(f\"Duplicate coordinates between files: {duplicate_count}\")\n",
    "print(f\"Difference coordinates_1: {total_complement_1}\")\n",
    "print(f\"Difference coordinates_2: {total_complement_2}\")\n",
    "print(f\"Ratio of duplicates (file 1): {duplicate_ratio_file1:.2%}\")\n",
    "print(f\"Ratio of duplicates (file 2): {duplicate_ratio_file2:.2%}\")\n",
    "print(f\"Ratio of duplicates (combined): {duplicate_ratio_combined:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "import random\n",
    "import jsonlines\n",
    "\n",
    "# 读取 JSONL 文件\n",
    "file_path = \"/workspace/ftg/lm_mmlu.json\"\n",
    "\n",
    "# with jsonlines.open(file_path, mode=\"r\") as reader:\n",
    "#     for obj in reader:\n",
    "#         print(obj)  # 每个 obj 是一个字典\n",
    "\n",
    "random.seed(42)\n",
    "# from src.module.func import scatter_plot, plot_points\n",
    "\n",
    "# 在 Jupyter 中交互式输入文件路径\n",
    "\n",
    "save_dir = \"./target_neurons\"\n",
    "# j1 = input(\"请输入第一个 JSONL 文件的路径: \")\n",
    "# j2 = input(\"请输入第二个 JSONL 文件的路径: \")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [12, 8]\n",
    "plt.rcParams[\"figure.dpi\"] = 120\n",
    "full_coord = set((x, y) for x in range(0, 24) for y in range(0, 896))\n",
    "print(f\"坐标总数: {len(full_coord)}\")\n",
    "\n",
    "def extract_coordinates(jsonl_file):\n",
    "    \"\"\"Extract coordinates from a JSONL file.\"\"\"\n",
    "    data = []\n",
    "    with jsonlines.open(jsonl_file, mode=\"r\") as reader:\n",
    "        for line in reader:\n",
    "            data.append(line[0])  # Parse each JSON line\n",
    "\n",
    "    # Extract coordinates\n",
    "    coordinates = []\n",
    "    for entry in data:\n",
    "        coordinates.extend([(item[0], item[1]) for item in entry[\"ig_gold\"]])\n",
    "    return coordinates\n",
    "\n",
    "\n",
    "def filter_counter(counter_obj):\n",
    "    # 计算平均值\n",
    "    mean_value = int(sum(counter_obj.values()) / len(counter_obj))\n",
    "    threshold = int(mean_value * 1)\n",
    "    # threshold = int(mean_value * 0.1)\n",
    "    # 过滤元素\n",
    "    filtered_counter = {\n",
    "        key: value for key, value in counter_obj.items() if value >= threshold\n",
    "    }\n",
    "\n",
    "    return filtered_counter\n",
    "\n",
    "\n",
    "def scatter_plot(counter_obj, highlight_duplicates=None):\n",
    "    x = [key[0] for key in counter_obj.keys()]\n",
    "    y = [key[1] for key in counter_obj.keys()]\n",
    "    sizes = [value * 0.1 for value in counter_obj.values()]  # 调整点大小以反映计数\n",
    "\n",
    "    plt.scatter(\n",
    "        x, y, s=sizes, alpha=0.6, color=\"skyblue\", edgecolor=\"black\", label=\"All Points\"\n",
    "    )\n",
    "\n",
    "    # Highlight duplicate points if provided\n",
    "    if highlight_duplicates:\n",
    "        dup_x = [key[0] for key in highlight_duplicates]\n",
    "        dup_y = [key[1] for key in highlight_duplicates]\n",
    "        plt.scatter(dup_x, dup_y, s=1, alpha=0.9, color=\"red\", label=\"Duplicates\")\n",
    "\n",
    "    plt.xlabel(\"X values\")\n",
    "    plt.ylabel(\"Y values\")\n",
    "    plt.title(\"Scatter plot of (x, y) counts\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Extract coordinates from both files\n",
    "coordinates_file1 = extract_coordinates(file_path)\n",
    "unique_coord = set(coordinates_file1)\n",
    "# Count occurrences in both files\n",
    "all_coord_counter = Counter(coordinates_file1)\n",
    "# 获取Counter中的所有键\n",
    "\n",
    "print(f\"去重高贡献坐标总数: {len(unique_coord)}\")\n",
    "\n",
    "# counter_file1 = filter_counter(counter_file1)\n",
    "# print(len(counter_file1))\n",
    "complement_coord = full_coord - unique_coord\n",
    "keys = list(complement_coord)\n",
    "\n",
    "# # 计算要抽取的元素数量，10%的元素\n",
    "# RATIO = 10\n",
    "# sample_size = max(1, int(len(keys) // RATIO))\n",
    "\n",
    "# # 随机抽取10%的元素\n",
    "# sampled_keys = random.sample(keys, sample_size)\n",
    "print(f\"非高贡献坐标总数: {len(complement_coord)}\")\n",
    "# print(len(sampled_keys))\n",
    "\n",
    "# 24* 4864 = 116736\n",
    "# counter_file2 = filter_counter(counter_file2)\n",
    "scatter_plot(all_coord_counter)\n",
    "# scatter_plot(Counter(sampled_keys))\n",
    "counter_file1_list = list(all_coord_counter)\n",
    "with open(f\"{save_dir}/complement_1.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(counter_file1_list, f, ensure_ascii=False, indent=4)\n",
    "# with open(f\"{save_dir}/random_RATIO{RATIO}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(sampled_keys, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "随机神经元坐标生成"
    ]
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "num_layer = 24\n",
    "num_neuron = 10\n",
    "\n",
    "# 生成包含随机整数的列表\n",
    "random_data = [random.sample(range(896), num_neuron) for _ in range(num_layer)]\n",
    "\n",
    "# 将数据写入 JSON 文件\n",
    "with open(\"random_neurons.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(random_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"JSON 文件已生成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
