{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "获取模型参数量"
    ]
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "# 加载模型\n",
    "model_name = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "model = AutoModel.from_pretrained(model_name, cache_dir=\"/cache/huggingface/hub\")\n",
    "\n",
    "# 计算总参数量\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "print(f\"模型的总参数量: {total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 比较模型参数差异并提取位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "from pprint import pprint\n",
    "import torch\n",
    "\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "\n",
    "def compare_mlp_params(model1, model2, mlp_layers: Union[str, List[str]]) -> dict:\n",
    "    \"\"\"比较多个MLP层的参数差异\n",
    "\n",
    "    Args:\n",
    "        mlp_layers: 支持以下格式：\n",
    "            - 单个层模式: \"transformer.h.0.mlp\"\n",
    "            - 多个层模式: [\"transformer.h.0.mlp\", \"transformer.h.5.mlp\"]\n",
    "    \"\"\"\n",
    "    # 统一处理为列表格式\n",
    "    if isinstance(mlp_layers, str):\n",
    "        target_patterns = [mlp_layers]\n",
    "    else:\n",
    "        target_patterns = mlp_layers\n",
    "\n",
    "    # 多模式参数提取\n",
    "    def filter_params(model):\n",
    "        return {\n",
    "            name: param\n",
    "            for name, param in model.named_parameters()\n",
    "            if any(pattern in name for pattern in target_patterns)\n",
    "        }\n",
    "\n",
    "    params1 = filter_params(model1)\n",
    "    params2 = filter_params(model2)\n",
    "\n",
    "    # 结构一致性检查\n",
    "    if params1.keys() != params2.keys():\n",
    "        missing_in_1 = set(params2.keys()) - set(params1.keys())\n",
    "        missing_in_2 = set(params1.keys()) - set(params2.keys())\n",
    "        raise ValueError(\n",
    "            f\"模型结构不一致\\n\"\n",
    "            f\"Model1缺失层: {list(missing_in_1)}\\n\"\n",
    "            f\"Model2缺失层: {list(missing_in_2)}\"\n",
    "        )\n",
    "\n",
    "    differences = {}\n",
    "\n",
    "    for name in params1:\n",
    "        p1, p2 = params1[name].cpu(), params2[name].cpu()\n",
    "\n",
    "        if p1.shape != p2.shape:\n",
    "            raise ValueError(f\"形状不匹配: {name} | {p1.shape} vs {p2.shape}\")\n",
    "\n",
    "        if not torch.equal(p1, p2):\n",
    "            diff_mask = ~torch.isclose(p1, p2, rtol=1e-5, atol=1e-8)\n",
    "            diff_indices = torch.unique(torch.nonzero(diff_mask)[:, 0])\n",
    "\n",
    "            differences[name] = {\n",
    "                \"shape\": tuple(p1.shape),\n",
    "                \"diff_ratio\": diff_indices.size(0) / p1.numel(),\n",
    "                \"diff_indices\": diff_indices.tolist(),\n",
    "            }\n",
    "\n",
    "    return differences\n",
    "\n",
    "\n",
    "# 使用示例\n",
    "if __name__ == \"__main__\":\n",
    "    # 单层比较\n",
    "    # diff = compare_mlp_params(model1_path, model2_path, \"transformer.h.0.mlp\")\n",
    "    model1_path = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "    model2_path = \"/cache/models/target_neurons_10R_reranker/results/target_neurons/checkpoint-285430\"\n",
    "    model1 = AutoModelForCausalLM.from_pretrained(\n",
    "        model1_path, torch_dtype=torch.bfloat16\n",
    "    )\n",
    "    model2 = AutoModelForCausalLM.from_pretrained(\n",
    "        model2_path, torch_dtype=torch.bfloat16\n",
    "    )\n",
    "    # for name, param in model1.named_parameters():\n",
    "    #     print(name)\n",
    "    target_modules = []\n",
    "    for idx, layer in enumerate(model1.model.layers):\n",
    "        module_str = f\"model.layers.{idx}.mlp.down_proj.weight\"\n",
    "        target_modules.append(module_str)\n",
    "    # 多层比较\n",
    "    diff = compare_mlp_params(model1, model2, mlp_layers=target_modules)\n",
    "    pprint(diff)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
