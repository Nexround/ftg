{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activations saved to ./activations/activations.json\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import json\n",
    "import os\n",
    "\n",
    "# 1. 加载 BERT 模型和 tokenizer\n",
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# 2. 定义一个字典来存储激活值\n",
    "activations = {}\n",
    "\n",
    "# 3. 定义钩子函数来捕获特定位置的激活值\n",
    "def hook_fn(layer_name, target_token_idx):\n",
    "    def hook(module, input, output):\n",
    "        # 获取特定token位置的激活值\n",
    "        # output的形状为 (batch_size, seq_len, hidden_size)\n",
    "        # 我们选定目标token的位置target_token_idx\n",
    "        target_activation = output.detach().cpu().numpy()[:, target_token_idx, :]\n",
    "        activations[layer_name] = target_activation.tolist()\n",
    "    return hook\n",
    "\n",
    "# 4. 注册钩子：遍历所有 Transformer 层并注册钩子\n",
    "hooks = []\n",
    "input_text = \"Hello, how are you?\"\n",
    "\n",
    "# 5. 将输入文本转换为token，并获取目标token的位置（如[CLS]或某个token）\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "tokens = tokenizer.tokenize(input_text)\n",
    "\n",
    "# 假设我们想要获取第一个token（[CLS]）的位置\n",
    "target_token_idx = 0  # [CLS]通常是第一个token\n",
    "\n",
    "# 6. 注册钩子到每一层的 intermediate.dense（FFN部分）\n",
    "for i, layer in enumerate(model.encoder.layer):\n",
    "    hook = layer.intermediate.dense.register_forward_hook(hook_fn(f\"layer_{i}_ffn\", target_token_idx))\n",
    "    hooks.append(hook)\n",
    "\n",
    "# 7. 执行前向传播\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# 8. 保存激活值到硬盘（保存为 JSON 格式）\n",
    "save_dir = \"./activations\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# 保存路径\n",
    "activation_file_path = os.path.join(save_dir, \"activations.json\")\n",
    "\n",
    "# 将激活值字典保存为 JSON 文件\n",
    "with open(activation_file_path, 'w') as json_file:\n",
    "    json.dump(activations, json_file)\n",
    "\n",
    "print(f\"Activations saved to {activation_file_path}\")\n",
    "\n",
    "# 9. 移除钩子\n",
    "for hook in hooks:\n",
    "    hook.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 3000000/3000000 [00:15<00:00, 191809.91 examples/s]\n",
      "Generating test split: 100%|██████████| 650000/650000 [00:03<00:00, 193685.20 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# from datasets import load_dataset\n",
    "# ds = load_dataset(\"coastalcph/lex_glue\", \"ecthr_a\", cache_dir=\"/cache/huggingface/datasets\")\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "\n",
    "# ds = load_dataset(\"nyu-mll/glue\",\"sst2\")\n",
    "from datasets import load_dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"yassiracharki/Amazon_Reviews_for_Sentiment_Analysis_fine_grained_5_classes\")\n",
    "# dataset = load_dataset(\"fancyzhx/ag_news\")\n",
    "# dataset = load_dataset(\"sem_eval_2018_task_1\", \"subtask5.english\")\n",
    "# ds = load_dataset(\"codyburker/yelp_review_sampled\", cache_dir=\"/cache/huggingface/datasets\")\n",
    "# ds = load_dataset(\"Yelp/yelp_review_full\", cache_dir=\"/cache/huggingface/datasets\")\n",
    "# model = BertForSequenceClassification.from_pretrained(\n",
    "#     \"distilbert-base-uncased\", num_labels=5, cache_dir=\"/cache/huggingface/hub\"\n",
    "# )\n",
    "# from transformers import DistilBertTokenizer, DistilBertModel\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "# model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "# ds = load_dataset(\"bookcorpus/bookcorpus\", cache_dir=\"/cache/huggingface/datasets\")\n",
    "# ds = load_dataset(\"bookcorpus/bookcorpus\", cache_dir=\"/cache/huggingface/datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 示例 Counter 对象\n",
    "data = Counter({'A': 10, 'B': 15, 'C': 5, 'D': 20})\n",
    "\n",
    "# 绘制直方图\n",
    "def plot_counter_histogram(counter_obj):\n",
    "    labels = list(counter_obj.keys())\n",
    "    values = list(counter_obj.values())\n",
    "\n",
    "    plt.bar(labels, values, color='skyblue', edgecolor='black')\n",
    "    plt.xlabel('Categories')\n",
    "    plt.ylabel('Counts')\n",
    "    plt.title('Histogram of Counter')\n",
    "    plt.show()\n",
    "\n",
    "# 调用函数绘制\n",
    "plot_counter_histogram(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.7593, -0.1422, -0.8351, -0.6397, -0.1545, -1.1371, -0.7905,  0.8253,\n",
      "          1.0648,  0.4474],\n",
      "        [ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
      "          0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 创建一个 Linear 层\n",
    "linear = nn.Linear(in_features=10, out_features=5)\n",
    "\n",
    "# 初始化输入\n",
    "x = torch.randn(1, 10)\n",
    "\n",
    "# 前向计算\n",
    "output = linear(x)\n",
    "\n",
    "# 钩子函数：仅保留第 i 个神经元的梯度\n",
    "i = 2\n",
    "def hook_fn(grad):\n",
    "    mask = torch.zeros_like(grad)\n",
    "    mask[i, :] = 1  # 仅保留第 i 行的梯度\n",
    "    return grad * mask\n",
    "\n",
    "linear.weight.register_hook(hook_fn)\n",
    "\n",
    "# 损失函数\n",
    "loss = output.sum()\n",
    "\n",
    "# 反向传播\n",
    "loss.backward()\n",
    "\n",
    "# 查看梯度\n",
    "print(linear.weight.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting environment information...\n",
      "PyTorch version: 2.6.0a0+df5bbc09d1.nv24.11\n",
      "Is debug build: False\n",
      "CUDA used to build PyTorch: 12.6\n",
      "ROCM used to build PyTorch: N/A\n",
      "\n",
      "OS: Ubuntu 24.04.1 LTS (x86_64)\n",
      "GCC version: (Ubuntu 13.2.0-23ubuntu4) 13.2.0\n",
      "Clang version: Could not collect\n",
      "CMake version: version 3.31.0\n",
      "Libc version: glibc-2.39\n",
      "\n",
      "Python version: 3.12.3 (main, Sep 11 2024, 14:17:37) [GCC 13.2.0] (64-bit runtime)\n",
      "Python platform: Linux-6.8.0-51-generic-x86_64-with-glibc2.39\n",
      "Is CUDA available: True\n",
      "CUDA runtime version: Could not collect\n",
      "CUDA_MODULE_LOADING set to: LAZY\n",
      "GPU models and configuration: GPU 0: NVIDIA GeForce RTX 4090\n",
      "Nvidia driver version: 560.35.05\n",
      "cuDNN version: Probably one of the following:\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn.so.9.5.1\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn_adv.so.9.5.1\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn_cnn.so.9.5.1\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn_engines_precompiled.so.9.5.1\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn_engines_runtime_compiled.so.9.5.1\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn_graph.so.9.5.1\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn_heuristic.so.9.5.1\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn_ops.so.9.5.1\n",
      "HIP runtime version: N/A\n",
      "MIOpen runtime version: N/A\n",
      "Is XNNPACK available: True\n",
      "\n",
      "CPU:\n",
      "Architecture:                         x86_64\n",
      "CPU op-mode(s):                       32-bit, 64-bit\n",
      "Address sizes:                        46 bits physical, 48 bits virtual\n",
      "Byte Order:                           Little Endian\n",
      "CPU(s):                               40\n",
      "On-line CPU(s) list:                  0-39\n",
      "Vendor ID:                            GenuineIntel\n",
      "Model name:                           Intel(R) Xeon(R) Silver 4210 CPU @ 2.20GHz\n",
      "CPU family:                           6\n",
      "Model:                                85\n",
      "Thread(s) per core:                   2\n",
      "Core(s) per socket:                   10\n",
      "Socket(s):                            2\n",
      "Stepping:                             7\n",
      "CPU(s) scaling MHz:                   42%\n",
      "CPU max MHz:                          3200.0000\n",
      "CPU min MHz:                          1000.0000\n",
      "BogoMIPS:                             4400.00\n",
      "Flags:                                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc cpuid aperfmperf pni pclmulqdq dtes64 monitor ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault epb cat_l3 cdp_l3 intel_ppin ssbd mba ibrs ibpb stibp ibrs_enhanced tpr_shadow flexpriority ept vpid ept_ad fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid cqm mpx rdt_a avx512f avx512dq rdseed adx smap clflushopt clwb intel_pt avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm ida arat pln pts vnmi pku ospke avx512_vnni md_clear flush_l1d arch_capabilities\n",
      "Virtualization:                       VT-x\n",
      "L1d cache:                            640 KiB (20 instances)\n",
      "L1i cache:                            640 KiB (20 instances)\n",
      "L2 cache:                             20 MiB (20 instances)\n",
      "L3 cache:                             27.5 MiB (2 instances)\n",
      "NUMA node(s):                         2\n",
      "NUMA node0 CPU(s):                    0-9,20-29\n",
      "NUMA node1 CPU(s):                    10-19,30-39\n",
      "Vulnerability Gather data sampling:   Mitigation; Microcode\n",
      "Vulnerability Itlb multihit:          KVM: Mitigation: VMX disabled\n",
      "Vulnerability L1tf:                   Not affected\n",
      "Vulnerability Mds:                    Not affected\n",
      "Vulnerability Meltdown:               Not affected\n",
      "Vulnerability Mmio stale data:        Mitigation; Clear CPU buffers; SMT vulnerable\n",
      "Vulnerability Reg file data sampling: Not affected\n",
      "Vulnerability Retbleed:               Mitigation; Enhanced IBRS\n",
      "Vulnerability Spec rstack overflow:   Not affected\n",
      "Vulnerability Spec store bypass:      Mitigation; Speculative Store Bypass disabled via prctl\n",
      "Vulnerability Spectre v1:             Mitigation; usercopy/swapgs barriers and __user pointer sanitization\n",
      "Vulnerability Spectre v2:             Mitigation; Enhanced / Automatic IBRS; IBPB conditional; RSB filling; PBRSB-eIBRS SW sequence; BHI SW loop, KVM SW loop\n",
      "Vulnerability Srbds:                  Not affected\n",
      "Vulnerability Tsx async abort:        Mitigation; TSX disabled\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] mypy-extensions==1.0.0\n",
      "[pip3] numpy==1.26.4\n",
      "[pip3] onnx==1.17.0\n",
      "[pip3] optree==0.13.1\n",
      "[pip3] pytorch-triton==3.0.0+72734f086\n",
      "[pip3] torch==2.6.0a0+df5bbc09d1.nv24.11\n",
      "[pip3] torch-tb-profiler==0.4.3\n",
      "[pip3] torch_tensorrt==2.6.0a0\n",
      "[pip3] torchprofile==0.0.4\n",
      "[pip3] torchvision==0.20.0a0\n",
      "[conda] Could not collect\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.collect_env import main\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 67349/67349 [00:00<00:00, 841374.34 examples/s]\n",
      "Generating validation split: 100%|██████████| 872/872 [00:00<00:00, 139139.96 examples/s]\n",
      "Generating test split: 100%|██████████| 1821/1821 [00:00<00:00, 212315.22 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels range: min = 0, max = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"glue\", \"sst2\")\n",
    "train_labels = dataset['train']['label']\n",
    "\n",
    "print(f\"Train labels range: min = {min(train_labels)}, max = {max(train_labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 302\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpprint\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pprint\n\u001b[1;32m    299\u001b[0m     pprint(model)\n\u001b[0;32m--> 302\u001b[0m \u001b[43mtest_custom_bert_for_masked_lm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 285\u001b[0m, in \u001b[0;36mtest_custom_bert_for_masked_lm\u001b[0;34m()\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# Compare the logits before and after the modification\u001b[39;00m\n\u001b[1;32m    284\u001b[0m difference \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(original_mask_logits \u001b[38;5;241m-\u001b[39m modified_mask_logits)\n\u001b[0;32m--> 285\u001b[0m forward_with_partitioning \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_with_partitioning\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# Print the results\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal logits for [MASK] position:\u001b[39m\u001b[38;5;124m\"\u001b[39m, original_mask_logits)\n",
      "Cell \u001b[0;32mIn[12], line 69\u001b[0m, in \u001b[0;36mCustomBertForMaskedLM.forward_with_partitioning\u001b[0;34m(self, target_position)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers):\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodify_ffn_activation(\n\u001b[1;32m     67\u001b[0m         idx, target_position, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_partitioning_activations[idx]\n\u001b[1;32m     68\u001b[0m     )\n\u001b[0;32m---> 69\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_partitioning_logits\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     71\u001b[0m         outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     72\u001b[0m     )  \u001b[38;5;66;03m# logits不可使用detach，否则会导致梯度丢失\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py:1461\u001b[0m, in \u001b[0;36mBertForMaskedLM.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1452\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1453\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1454\u001b[0m \u001b[38;5;124;03m    Labels for computing the masked language modeling loss. Indices should be in `[-100, 0, ...,\u001b[39;00m\n\u001b[1;32m   1455\u001b[0m \u001b[38;5;124;03m    config.vocab_size]` (see `input_ids` docstring) Tokens with indices set to `-100` are ignored (masked), the\u001b[39;00m\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;124;03m    loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[1;32m   1457\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1459\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1461\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1467\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1468\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1469\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1471\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1472\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1473\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1475\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1476\u001b[0m prediction_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcls(sequence_output)\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1142\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    686\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m         output_attentions,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py:627\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    624\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    625\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 627\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/pytorch_utils.py:258\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 258\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/bert/modeling_bert.py:639\u001b[0m, in \u001b[0;36mBertLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 639\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    640\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1844\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1846\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[1;32m   1849\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py:1803\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1801\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, args, kwargs, result)\n\u001b[1;32m   1802\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1803\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hook_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1806\u001b[0m     result \u001b[38;5;241m=\u001b[39m hook_result\n",
      "Cell \u001b[0;32mIn[12], line 152\u001b[0m, in \u001b[0;36mCustomBertForMaskedLM.modify_ffn_activation.<locals>.hook_fn\u001b[0;34m(module, input, output)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_activations\u001b[38;5;241m.\u001b[39mappend(output\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# Ensure the shape matches\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m batch_idx, seq_idx \u001b[38;5;241m=\u001b[39m target_position\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_activation\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m output[batch_idx, seq_idx]\u001b[38;5;241m.\u001b[39mshape:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape mismatch: Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput[batch_idx,\u001b[38;5;250m \u001b[39mseq_idx]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_activation\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": [
    "from transformers import BertForMaskedLM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "from transformers import BertForMaskedLM\n",
    "import torch\n",
    "\n",
    "from transformers import BertForMaskedLM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CustomBertForMaskedLM(BertForMaskedLM):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self._intermediate_activations = []\n",
    "        self._original_activations = []\n",
    "        self._mask_logits = None\n",
    "        self._partitioning_activations = []\n",
    "        self._partitioning_step = []\n",
    "        self._partitioning_logits = []\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        保存现有参数以用于forward_with_partitioning\n",
    "        \"\"\"\n",
    "        self._args = args\n",
    "        self._kwargs = kwargs\n",
    "\n",
    "        # Hook to capture intermediate activations\n",
    "        def hook_fn(module, input, output):\n",
    "            # 如果 _intermediate_activations 不为空，则清空它\n",
    "            if len(self._intermediate_activations) == self.config.num_hidden_layers:\n",
    "                self._intermediate_activations.clear()\n",
    "\n",
    "            # 添加新的激活到 _intermediate_activations\n",
    "            self._intermediate_activations.append(output.detach().cpu())\n",
    "\n",
    "        # Register hooks on intermediate layers\n",
    "        hooks = []\n",
    "        for layer in self.bert.encoder.layer:\n",
    "            hooks.append(layer.intermediate.register_forward_hook(hook_fn))\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = super().forward(*args, **kwargs)\n",
    "        # Remove hooks after forward pass\n",
    "        for hook in hooks:\n",
    "            hook.remove()\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def forward_with_partitioning(self, target_position=3):\n",
    "        \"\"\"\n",
    "        target_pos token idx\n",
    "        \"\"\"\n",
    "        for layer in self._intermediate_activations:\n",
    "            target_vector = layer[:, target_position, :]\n",
    "            partitioning, step = self.generate_partitioning(target_vector)\n",
    "            self._partitioning_activations.append(partitioning.detach().cpu())\n",
    "            self._partitioning_step.append(step.detach().cpu())\n",
    "\n",
    "        # Forward pass\n",
    "        for idx in range(self.config.num_hidden_layers):\n",
    "            self.modify_ffn_activation(\n",
    "                idx, target_position, self._partitioning_activations[idx]\n",
    "            )\n",
    "            outputs = super().forward(*self._args, **self._kwargs)\n",
    "            self._partitioning_logits.append(\n",
    "                outputs.logits\n",
    "            )  # logits不可使用detach，否则会导致梯度丢失\n",
    "        \n",
    "        pass\n",
    "\n",
    "\n",
    "    def get_mask_logits(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Returns logits at [MASK] positions for the given input.\n",
    "        \"\"\"\n",
    "        self.eval()  # Ensure model is in eval mode\n",
    "        with torch.no_grad():\n",
    "            outputs = self.forward(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, return_dict=True\n",
    "            )\n",
    "            logits = outputs.logits\n",
    "\n",
    "        # Find [MASK] token positions (token_id=103 for BERT by default)\n",
    "        mask_token_id = 103\n",
    "        # mask_token_id = self.config.mask_token_id\n",
    "        mask_positions = input_ids == mask_token_id\n",
    "\n",
    "        # Extract logits for [MASK] positions\n",
    "        mask_logits = logits[mask_positions]\n",
    "\n",
    "        return mask_logits\n",
    "\n",
    "    @property\n",
    "    def get_intermediate_activations(self):\n",
    "        \"\"\"\n",
    "        Returns the intermediate neuron activations from the last forward pass.\n",
    "        Raises an error if intermediate_activations is empty.\n",
    "        \"\"\"\n",
    "        if not self._intermediate_activations:\n",
    "            raise ValueError(\n",
    "                \"Intermediate activations are empty. Ensure that a forward pass has been performed.\"\n",
    "            )\n",
    "        return self._intermediate_activations\n",
    "\n",
    "    @property\n",
    "    def original_activations(self):\n",
    "        \"\"\"\n",
    "        Returns the original (before modification) intermediate neuron activations.\n",
    "        \"\"\"\n",
    "        if not self._original_activations:\n",
    "            raise ValueError(\n",
    "                \"Original activations are empty. Ensure that a forward pass has been performed.\"\n",
    "            )\n",
    "        return self._original_activations\n",
    "\n",
    "    @property\n",
    "    def mask_logits(self):\n",
    "        \"\"\"\n",
    "        Returns the logits at [MASK] positions from the last forward pass.\n",
    "        Raises an error if _mask_logits is None.\n",
    "        \"\"\"\n",
    "        if self._mask_logits is None:\n",
    "            raise ValueError(\n",
    "                \"Mask logits are not available. Ensure that a forward pass has been performed with [MASK] tokens.\"\n",
    "            )\n",
    "        return self._mask_logits\n",
    "\n",
    "    def modify_ffn_activation(self, layer_idx, target_position, new_activation):\n",
    "        \"\"\"\n",
    "        Modifies the hidden activations of a specific FFN layer at a specific position in the model.\n",
    "        Stores the original activations before modifying.\n",
    "\n",
    "        Args:\n",
    "            layer_idx (int): Index of the transformer layer to modify (0-indexed).\n",
    "            target_position (tuple): A tuple specifying the target position (batch_idx, seq_idx).\n",
    "            new_activation (torch.Tensor): The new activation values with shape matching the FFN layer output\n",
    "                                            (e.g., [intermediate_size]).\n",
    "        \"\"\"\n",
    "        if not isinstance(new_activation, torch.Tensor):\n",
    "            raise ValueError(\"new_activation must be a torch.Tensor.\")\n",
    "\n",
    "        def hook_fn(module, input, output):\n",
    "            # Store original activations before modification\n",
    "            self._original_activations.append(output.detach().cpu())\n",
    "\n",
    "            # Ensure the shape matches\n",
    "            batch_idx, seq_idx = target_position\n",
    "            if new_activation.shape != output[batch_idx, seq_idx].shape:\n",
    "                raise ValueError(\n",
    "                    f\"Shape mismatch: Expected {output[batch_idx, seq_idx].shape}, \"\n",
    "                    f\"but got {new_activation.shape}.\"\n",
    "                )\n",
    "\n",
    "            # Modify the activation at the target position\n",
    "            output = output.clone()  # Clone to avoid in-place modification\n",
    "            output[batch_idx, seq_idx] = new_activation\n",
    "            return output\n",
    "\n",
    "        # Register the hook\n",
    "        hook = self.bert.encoder.layer[layer_idx].intermediate.register_forward_hook(\n",
    "            hook_fn\n",
    "        )\n",
    "        \"\"\"\n",
    "        这个函数利用hook修改指定位置上的FFN层的激活值，并存储修改前的激活值。\n",
    "        \"\"\"\n",
    "        return hook  # Return the hook handle for later removal if needed\n",
    "\n",
    "    def generate_partitioning(self, vector, times=20):\n",
    "        \"\"\"\n",
    "        生成一组按比例缩放的输入数据。\n",
    "\n",
    "        参数:\n",
    "            emb (torch.Tensor): 输入张量，形状为 (1, ffn_size)，表示一个基准向量。\n",
    "            batch_size (int): 每个批次中的样本数量。\n",
    "            num_batch (int): 批次的总数量。\n",
    "\n",
    "        返回:\n",
    "            partitioning (torch.Tensor): 形状为 (batch_size * num_batch, ffn_size) 的张量，包含生成的缩放输入。\n",
    "            step (torch.Tensor): 每次增量的大小，形状为 (1, ffn_size)，表示每一步的变化量。\n",
    "        equal partitioning\n",
    "\n",
    "        \"\"\"\n",
    "        vector = vector\n",
    "        # vector = vector.unsqueeze(0)\n",
    "        baseline = torch.zeros_like(vector)  # (1, ffn_size)\n",
    "\n",
    "        # step: 计算每一步的增量，即 emb 和 baseline 之间的差距除以总的样本数。\n",
    "        # 这是为了确保从 baseline 到 emb 的变化是均匀的，按比例分配给每个样本。\n",
    "        step = (vector - baseline) / times  # (1, ffn_size) # 每个分量上的间隔值\n",
    "\n",
    "        # res: 使用 baseline 和 step 生成 scaled input 的列表。\n",
    "        # 通过 torch.add 和 step * i 逐步构建每个样本的值，并将这些值沿着第一个维度 (batch_size * num_batch) 拼接。\n",
    "        partitioning = torch.cat(\n",
    "            [torch.add(baseline, step * i) for i in range(times)], dim=0\n",
    "        )  # (step, ffn_size)\n",
    "\n",
    "        # 返回生成的输入数据和每一步的增量。\n",
    "        return partitioning, step[0]\n",
    "\n",
    "    # @staticmethod\n",
    "    def calulate_integrated_gradients(self, logits, target_label, partitioning, step):\n",
    "\n",
    "        prob = F.softmax(logits, dim=1)\n",
    "        o = torch.unbind(prob[:, target_label])\n",
    "        gradient = torch.autograd.grad(o, partitioning).sequeeze(0)\n",
    "        grad_summed = gradient.sum(dim=0)  # (ffn_size)\n",
    "        ig_pred = grad_summed * step  # (ffn_size)\n",
    "        return ig_pred\n",
    "\n",
    "\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from transformers import BertForMaskedLM\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Assuming CustomBertForMaskedLM is defined as per the provided code\n",
    "\n",
    "\n",
    "def test_custom_bert_for_masked_lm():\n",
    "    # Check if CUDA is available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Load pre-trained BERT model and tokenizer\n",
    "    model_name = \"bert-base-uncased\"\n",
    "    tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "    config = BertConfig.from_pretrained(model_name)\n",
    "\n",
    "    # Instantiate the model and move it to the appropriate device (CPU or GPU)\n",
    "    model = CustomBertForMaskedLM(config).to(device)\n",
    "\n",
    "    # Load pre-trained weights into the custom model\n",
    "    model.bert.load_state_dict(\n",
    "        BertForMaskedLM.from_pretrained(model_name).bert.state_dict()\n",
    "    )\n",
    "\n",
    "    # Tokenize some example input text with a [MASK] token\n",
    "    text = \"The quick brown fox jumps over the [MASK] dog.\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "    # Move input tensors to the same device as the model\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "    attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "\n",
    "    # Perform the first forward pass to get original logits (before modification)\n",
    "    original_outputs = model(\n",
    "        input_ids=input_ids, attention_mask=attention_mask, return_dict=True\n",
    "    )\n",
    "    original_logits = original_outputs.logits\n",
    "\n",
    "    # Get the original logits for the [MASK] position\n",
    "    mask_token_id = 103\n",
    "    mask_positions = input_ids == mask_token_id\n",
    "    original_mask_logits = original_logits[mask_positions]\n",
    "\n",
    "    # Modify the activations of a specific FFN layer and position\n",
    "    target_position = (\n",
    "        0,\n",
    "        5,\n",
    "    )  # Example: batch_idx = 0, seq_idx = 5 (corresponding to the [MASK] token)\n",
    "    new_activation = torch.randn(model.config.intermediate_size).to(\n",
    "        device\n",
    "    )  # Random tensor of appropriate size\n",
    "\n",
    "    # Modify the activation in the 3rd transformer layer\n",
    "    hook = model.modify_ffn_activation(\n",
    "        layer_idx=2, target_position=target_position, new_activation=new_activation\n",
    "    )\n",
    "\n",
    "    # Perform the second forward pass after modification\n",
    "    modified_outputs = model(\n",
    "        input_ids=input_ids, attention_mask=attention_mask, return_dict=True\n",
    "    )\n",
    "    modified_logits = modified_outputs.logits\n",
    "\n",
    "    # Get the modified logits for the [MASK] position\n",
    "    modified_mask_logits = modified_logits[mask_positions]\n",
    "\n",
    "    # Compare the logits before and after the modification\n",
    "    difference = torch.abs(original_mask_logits - modified_mask_logits)\n",
    "    forward_with_partitioning = model.forward_with_partitioning(target_position=5)\n",
    "    # Print the results\n",
    "    print(\"Original logits for [MASK] position:\", original_mask_logits)\n",
    "    print(\"Modified logits for [MASK] position:\", modified_mask_logits)\n",
    "    print(\"Difference between original and modified logits:\", difference)\n",
    "    print(f\"Maximum difference: {difference.max()}\")  # Print the maximum difference\n",
    "    partitioning, step = model.generate_partitioning(new_activation, times=20)\n",
    "    re = model.calulate_integrated_gradients(\n",
    "        original_logits, target_label=0, partitioning=partitioning, step=step\n",
    "    )\n",
    "    # Optionally remove the hook after testing\n",
    "    hook.remove()\n",
    "    from pprint import pprint\n",
    "\n",
    "    pprint(model)\n",
    "\n",
    "\n",
    "test_custom_bert_for_masked_lm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 打印显存统计信息\n",
    "print(torch.cuda.memory_stats())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740a43b5d0b24a2daf75449d0b6de353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassifications\n",
    "\n",
    "# 加载第一个模型\n",
    "fine_tuned_bert_model = BertForSequenceClassification.from_pretrained(\"/openbayes/home/ftg/results/agnews_checkpoint-22500\")\n",
    "\n",
    "# 加载第二个模型\n",
    "fine_tuned_classifier_model = BertForSequenceClassification.from_pretrained(\"/openbayes/home/ftg/results/train_full_imdb\")\n",
    "\n",
    "# 新建一个 BertForSequenceClassification 实例\n",
    "combined_model = BertForSequenceClassification.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# 将 BertModel 的权重替换为第一个微调模型的权重\n",
    "combined_model.bert = fine_tuned_bert_model.bert\n",
    "\n",
    "# 将 classifier 的权重替换为第二个微调模型的权重\n",
    "combined_model.classifier.load_state_dict(fine_tuned_classifier_model.classifier.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
